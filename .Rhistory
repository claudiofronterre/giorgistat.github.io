server <- function(input, output) {
observeEvent(input$simulate, {
h_vals <- seq(0, sqrt(2), length.out = 100)
corr_vals <- sapply(h_vals, matern_corr, kappa = input$kappa, phi = input$phi)
output$maternPlot <- renderPlot({
ggplot(data.frame(h = h_vals, corr = corr_vals), aes(x = h, y = corr)) +
geom_line() +
labs(title = "Matérn Correlation Function", x = "Distance h", y = "Correlation")
})
# Simulating a Spatial Field
grid_size <- 50
x <- seq(0, 1, length.out = grid_size)
y <- seq(0, 1, length.out = grid_size)
grid <- expand.grid(x = x, y = y)
coordinates(grid) <- ~x + y
grid <- st_as_sf(grid)
st_crs(grid) <- 3857
# Define the variogram model (Matérn covariance)
sim_res <-
glgpm_sim(n_sim = 1,
formula = ~ gp(kappa = input$kappa),
data = grid,
family = "gaussian",
crs = 3857,
sim_pars = list(beta = 0, sigma2 = input$sigma2,
phi = input$phi,
tau2 = 0, sigma2_me = 0),
scale_to_km = FALSE)
# Convert the result to a data frame for ggplot
sim_df <- data.frame(x = st_coordinates(grid)[,1],
y = st_coordinates(grid)[,2],
value = sim_res$data_sim$`_sim1`)
output$simulationPlot <- renderPlot({
ggplot(sim_df, aes(x = x, y = y, fill = value)) +
geom_tile() +
scale_fill_viridis_c() +
theme_minimal() +
labs(title = "Simulated Matérn GP Surface", fill = "Value")
})
})
}
# Run the application
shinyApp(ui = ui, server = server)
rm(list = ls())
library(RiskMap)
data(""galicia"")
data("galicia")
?galicia
galicia$lead
galicia <- st_as_sf(galicia, coords = c("x", "y"),
crs = 32629)
ggplot() + geom_sf(data = galicia, fill = lead)
rm(list = ls())
library(RiskMap)
library(sf)
library(ggplot2)
# Assuming 'galicia' is already loaded as a data frame
# Convert to an sf object
galicia <- st_as_sf(galicia, coords = c("x", "y"), crs = 32629)
# Plot the data
ggplot() +
geom_sf(data = galicia, aes(fill = lead))
galicia$lead
# Plot the data
leaflet::leaflet(galicia)
rm(list = ls())
library(RiskMap)
library(sf)
data("galicia")
# Convert to an sf object
galicia <- st_as_sf(galicia, coords = c("x", "y"), crs = 32629)
# Plot the data
leaflet::leaflet(galicia)
rm(list = ls())
library(RiskMap)
library(sf)
library(ggplot2)
data("galicia")
rm(list = ls())
library(RiskMap)
library(sf)
library(ggplot2)
data("galicia")
# Plot the data
leaflet::leaflet(galicia)
ggplot(data = galicia) +
geom_sf(aes(color = lead)) +
scale_color_viridis_c() +
theme_minimal() +
labs(title = "",
color = "Lead conc.")
ggplot(data = galicia) +
geom_sf(aes(color = lead)) +
theme_minimal() +
labs(title = "",
color = "Lead conc.")
rm(list = ls())
library(RiskMap)
library(sf)
library(ggplot2)
data("galicia")
# Convert to an sf object
galicia <- st_as_sf(galicia, coords = c("x", "y"), crs = 32629)
ggplot(data = galicia) +
geom_sf(aes(color = lead)) +
theme_minimal() +
labs(title = "",
color = "Lead conc.")
rm(list = ls())
library(RiskMap)
library(sf)
library(ggplot2)
data("galicia")
# Convert to an sf object
galicia <- st_as_sf(galicia, coords = c("x", "y"), crs = 32629)
ggplot(data = galicia) +
geom_sf(aes(color = lead)) +
scale_color_viridis_c() +
theme_minimal() +
labs(title = "",
color = "Lead conc.")
ggplot(data = galicia) +
geom_sf(aes(color = lead, size = lead)) +
scale_color_viridis_c() +
theme_minimal() +
labs(title = "",
color = "Lead conc.")
# Compute the variogram, using the residuals from the linear model fit,
# and the 95% confidence level envelope for spatial independence
galicia_variog <- s_variogram(galicia_sf, variable = "residuals",
scale_to_km = TRUE,
bins = seq(10, 140, length = 15),
n_permutation = 10000)
rm(list = ls())
library(RiskMap)
library(sf)
library(ggplot2)
data("galicia")
# Convert to an sf object
galicia_sf <- st_as_sf(galicia, coords = c("x", "y"), crs = 32629)
ggplot(data = galicia_sf) +
geom_sf(aes(color = lead, size = lead)) +
scale_color_viridis_c() +
theme_minimal() +
labs(title = "",
color = "Lead conc.")
# Compute the variogram, using the residuals from the linear model fit,
# and the 95% confidence level envelope for spatial independence
galicia_variog <- s_variogram(galicia_sf, variable = "residuals",
scale_to_km = TRUE,
bins = seq(10, 140, length = 15),
n_permutation = 10000)
rm(list = ls())
library(RiskMap)
library(sf)
library(ggplot2)
data("galicia")
# Convert to an sf object
galicia_sf <- st_as_sf(galicia, coords = c("x", "y"), crs = 32629)
ggplot(data = galicia_sf) +
geom_sf(aes(color = lead, size = lead)) +
scale_color_viridis_c() +
theme_minimal() +
labs(title = "",
color = "Lead conc.")
lm_fit <- lm(log(lead) ~ 1, data = galicia)
galicia$residuals <- lm_fit$residuals
# Compute the variogram, using the residuals from the linear model fit,
# and the 95% confidence level envelope for spatial independence
galicia_variog <- s_variogram(galicia_sf, variable = "residuals",
scale_to_km = TRUE,
bins = seq(10, 140, length = 15),
n_permutation = 10000)
lm_fit <- lm(log(lead) ~ 1, data = galicia)
galicia$residuals <- lm_fit$residuals
rm(list = ls())
library(RiskMap)
library(sf)
library(ggplot2)
data("galicia")
# Convert to an sf object
galicia_sf <- st_as_sf(galicia, coords = c("x", "y"), crs = 32629)
ggplot(data = galicia_sf) +
geom_sf(aes(color = lead, size = lead)) +
scale_color_viridis_c() +
theme_minimal() +
labs(title = "",
color = "Lead conc.")
lm_fit <- lm(log(lead) ~ 1, data = galicia_sf)
galicia_sf$residuals <- lm_fit$residuals
# Compute the variogram, using the residuals from the linear model fit,
# and the 95% confidence level envelope for spatial independence
galicia_variog <- s_variogram(galicia_sf, variable = "residuals",
scale_to_km = TRUE,
bins = seq(10, 140, length = 15),
n_permutation = 10000)
# Plotting the results
plot_s_variogram(galicia_variog, plot_envelope = TRUE)
# Plotting the results
plot_s_variogram(galicia_variog, plot_envelope = TRUE)
# Fit a linear geostatistical model
fit_galicia <-
glgpm(log(lead) ~ gp(x, y, kappa = 1.5), data=galicia, family = "gaussian",
crs = 32629, scale_to_km = TRUE, messages = FALSE)
summary(fit_galicia)
coef(fit_galicia)
par_hat <- coef(fit_galicia)
par_hat$sigma2
par_hat$phi
# Given parameters
sigma2 <- par_hat$sigma2
phi <- par_hat$phi
# Compute the practical range where correlation = 0.05
practical_range <- -phi * log(0.05)
# Define distance values for plotting
h <- seq(0, practical_range * 1.2, length.out = 100)
variogram <- sigma2 * (1 - exp(-h / phi))
# Plot the variogram
plot(h, variogram, type = "l", col = "blue", lwd = 2,
xlab = "Distance (h)", ylab = "Semivariance γ(h)",
main = "Theoretical Variogram (Exponential Model)")
# Plot the variogram
plot(h, variogram, type = "l", col = "blue", lwd = 2,
xlab = "Distance (h)", ylab = "Variogram γ(h)",
main = "Theoretical Variogram (Exponential Model)")
# Add vertical line for practical range
abline(v = practical_range, col = "red", lty = 2)
# Add legend
legend("bottomright", legend = c("Theoretical Variogram", "Practical Range"),
col = c("blue", "red"), lty = c(1, 2), lwd = c(2, 1))
rm(list = ls())
library(RiskMap)
library(sf)
library(ggplot2)
data("galicia")
# Convert to an sf object
galicia_sf <- st_as_sf(galicia, coords = c("x", "y"), crs = 32629)
ggplot(data = galicia_sf) +
geom_sf(aes(color = lead, size = lead)) +
scale_color_viridis_c() +
theme_minimal() +
labs(title = "",
color = "Lead conc.")
lm_fit <- lm(log(lead) ~ 1, data = galicia_sf)
galicia_sf$residuals <- lm_fit$residuals
# Compute the variogram, using the residuals from the linear model fit,
# and the 95% confidence level envelope for spatial independence
galicia_variog <- s_variogram(galicia_sf, variable = "residuals",
scale_to_km = TRUE,
bins = seq(10, 140, length = 15),
n_permutation = 10000)
# Plotting the results
plot_s_variogram(galicia_variog, plot_envelope = TRUE)
# Fit a linear geostatistical model
fit_galicia <-
glgpm(log(lead) ~ gp(x, y, kappa = 1.5), data=galicia, family = "gaussian",
crs = 32629, scale_to_km = TRUE, messages = FALSE)
summary(fit_galicia)
# Given parameters
sigma2 <- par_hat$sigma2
rm(list = ls())
library(RiskMap)
library(sf)
library(ggplot2)
data("galicia")
# Convert to an sf object
galicia_sf <- st_as_sf(galicia, coords = c("x", "y"), crs = 32629)
ggplot(data = galicia_sf) +
geom_sf(aes(color = lead, size = lead)) +
scale_color_viridis_c() +
theme_minimal() +
labs(title = "",
color = "Lead conc.")
lm_fit <- lm(log(lead) ~ 1, data = galicia_sf)
galicia_sf$residuals <- lm_fit$residuals
# Compute the variogram, using the residuals from the linear model fit,
# and the 95% confidence level envelope for spatial independence
galicia_variog <- s_variogram(galicia_sf, variable = "residuals",
scale_to_km = TRUE,
bins = seq(10, 140, length = 15),
n_permutation = 10000)
# Plotting the results
plot_s_variogram(galicia_variog, plot_envelope = TRUE)
# Fit a linear geostatistical model
fit_galicia <-
glgpm(log(lead) ~ gp(x, y, kappa = 1.5), data=galicia, family = "gaussian",
crs = 32629, scale_to_km = TRUE, messages = FALSE)
summary(fit_galicia)
# Maximum likelihood estimates
par_hat <- coef(fit_galicia)
# Given parameters
sigma2 <- par_hat$sigma2
phi <- par_hat$phi
# Compute the practical range where correlation = 0.05
practical_range <- -phi * log(0.05)
# Define distance values for plotting
h <- seq(0, practical_range * 1.2, length.out = 100)
variogram <- sigma2 * (1 - exp(-h / phi))
# Plot the variogram
plot(h, variogram, type = "l", col = "blue", lwd = 2,
xlab = "Distance (h)", ylab = "Variogram γ(h)",
main = "Theoretical Variogram (Exponential Model)")
# Add vertical line for practical range
abline(v = practical_range, col = "red", lty = 2)
# Add legend
legend("upperleft", legend = c("Theoretical Variogram", "Practical Range"),
col = c("blue", "red"), lty = c(1, 2), lwd = c(2, 1))
# Add legend
legend("topleft", legend = c("Theoretical Variogram", "Practical Range"),
col = c("blue", "red"), lty = c(1, 2), lwd = c(2, 1))
library(elevatr)
rm(list=ls())
source("auxiliary_function.R")
setwd("~/Desktop/Teaching/Time series analysis in epidemiology (CHIC662)/R code")
rm(list=ls())
source("auxiliary_function.R")
mal <- read.csv("Kericho.csv")
mal$Month <- factor(mal$Month,
levels=c("Jan","Feb","Mar","Apr","May","Jun","Jul",
"Aug","Sep","Oct","Nov","Dec"),ordered = TRUE)
mal$t <- as.numeric(mal$Month) + 12*(mal$Year-1979)
### Point 1
create.lag.var <- function(x,lag) {
tlag <- mal$t-lag
ind.lag <- sapply(tlag,function(x) {
out <- which((mal$t-x)==0)
if(length(out)==0) out <- NA
return(out)
})
x[ind.lag]
}
mal$minT.lag2 <-create.lag.var(mal$minT,lag=2)
mal$maxT.lag2 <-create.lag.var(mal$maxT,lag=2)
mal$Rain.lag2 <-create.lag.var(mal$Rain,lag=2)
mal <- mal[complete.cases(mal),]
matern.fit <-
fit.matern(form = log(Cases)~t + I((t>50)*(t-50)) + I(t>225)+
minT.lag2 + maxT.lag2 + Rain.lag2,data=mal,
time="t",kappa=2.5,start.cov.pars=c(1,1),
method="nlminb")
summary(matern.fit)
get.CI <- function(fitted.model) {
s.model <- summary(fitted.model)
reg.coef <-
cbind(s.model$coefficients[,1],
s.model$coefficients[,1]-qnorm(0.975)*s.model$coefficients[,2],
s.model$coefficients[,1]+qnorm(0.975)*s.model$coefficients[,2])
cov.pars <- exp(
cbind(s.model$cov.pars[,1],
s.model$cov.pars[,1]-qnorm(0.975)*s.model$cov.pars[,2],
s.model$cov.pars[,1]+qnorm(0.975)*s.model$cov.pars[,2]))
tab <- rbind(reg.coef,cov.pars)
rownames(tab)[(nrow(tab)-2):nrow(tab)] <- c("sigmaˆ2","phi","tauˆ2")
colnames(tab) <- c("Estimate","Lower limit","Upper limit")
tab
}
get.CI(matern.fit)
0.63970008*3
### Point 2
pred <- time.predict(matern.fit,
predictors = data.frame(t=mal$t,minT.lag2=mal$minT.lag2,
maxT.lag2=mal$maxT.lag2,
Rain.lag2=mal$Rain.lag2),
time.pred = mal$t,scale.pred = "linear")
matplot(pred$time.pred,cbind(pred$predictions,pred$quantiles),
lty=c("solid","dashed","dashed"),type="l",col=1)
points(mal$t,log(mal$Cases),pch=20,col=2)
pred <- time.predict(matern.fit,
predictors = data.frame(t=mal$t,minT.lag2=mal$minT.lag2,
maxT.lag2=mal$maxT.lag2,
Rain.lag2=mal$Rain.lag2),
time.pred = mal$t,scale.pred = "linear")
matplot(pred$time.pred,cbind(pred$predictions,pred$quantiles),
lty=c("solid","dashed","dashed"),type="l",col=1)
points(mal$t,log(mal$Cases),pch=20,col=2)
0.05*nrow(mal)
### Point 3
# year.holdout: is the number of years that are part of the holdout data-set
year.holdout <- 1
# year.holdout: is the number of years that are part of the holdout data-set
year.holdout <- 1
time.split <- max(mal$t)-year.holdout*12
# Identify the rows in the data-set that correspond to the training data-set
train <- which(mal$t<=time.split)
# Identify the rows in the data-set that correspond to the holdout data-set
holdout <- which(mal$t>time.split)
matern.fit.train <- fit.matern(form = log(Cases)~t + I((t>50)*(t-50)) + I(t>225)+
minT.lag2 + maxT.lag2 + Rain.lag2,
data=mal[train,],time="t",kappa=2.5,
start.cov.pars=c(1,1),method="nlminb")
t.pred.holdout <- mal$t[holdout]
pred.holdout <- time.predict(fitted.model=matern.fit.train,
predictors = data.frame(t=t.pred.holdout,
minT.lag2=mal$minT.lag2[holdout],
maxT.lag2=mal$maxT.lag2[holdout],
Rain.lag2=mal$Rain.lag2[holdout]),
time.pred = t.pred.holdout,scale.pred = "linear")
matplot(pred.holdout$time.pred,cbind(pred.holdout$predictions,pred.holdout$quantiles),
lty=c("solid","dashed","dashed"),type="l",col=1,
ylab="log(Cases)",xlab="Time")
points(mal[holdout,]$t,log(mal[holdout,]$Cases),pch=20)
# Bias
mean((pred.holdout$predictions-log(mal[holdout,]$Cases)))
# Mean-square error
mean((pred.holdout$predictions-log(mal[holdout,]$Cases))ˆ2)
# year.holdout: is the number of years that are part of the holdout data-set
year.holdout <- 1
time.split <- max(mal$t)-year.holdout*12
# Identify the rows in the data-set that correspond to the training data-set
train <- which(mal$t<=time.split)
# Identify the rows in the data-set that correspond to the holdout data-set
holdout <- which(mal$t>time.split)
matern.fit.train <- fit.matern(form = log(Cases)~t + I((t>50)*(t-50)) + I(t>225)+
minT.lag2 + maxT.lag2 + Rain.lag2,
data=mal[train,],time="t",kappa=2.5,
start.cov.pars=c(1,1),method="nlminb")
t.pred.holdout <- mal$t[holdout]
pred.holdout <- time.predict(fitted.model=matern.fit.train,
predictors = data.frame(t=t.pred.holdout,
minT.lag2=mal$minT.lag2[holdout],
maxT.lag2=mal$maxT.lag2[holdout],
Rain.lag2=mal$Rain.lag2[holdout]),
time.pred = t.pred.holdout,scale.pred = "linear")
matplot(pred.holdout$time.pred,cbind(pred.holdout$predictions,pred.holdout$quantiles),
lty=c("solid","dashed","dashed"),type="l",col=1,
ylab="log(Cases)",xlab="Time")
points(mal[holdout,]$t,log(mal[holdout,]$Cases),pch=20)
# Bias
mean((pred.holdout$predictions-log(mal[holdout,]$Cases)))
# Mean-square error
mean((pred.holdout$predictions-log(mal[holdout,]$Cases))ˆ2)
# Bias
mean((pred.holdout$predictions-log(mal[holdout,]$Cases)))
# Mean-square error
mean((pred.holdout$predictions-log(mal[holdout,]$Cases))^2)
# Mean-square error
sqrt(mean((pred.holdout$predictions-log(mal[holdout,]$Cases))^2))
# Point 4
matern.fit.with.sin <- fit.matern(form=
log(Cases) ~ t+I((t-50)*(t>50))+I(t>229)+sin(2*pi*t/12)+cos(2*pi*t/12)+
sin(2*pi*t/6)+cos(2*pi*t/6),time="t",start.cov.pars = c(1,5),
kappa=2.5,data=mal[train,], # NOTE: selecting the training data
method="nlminb")
pred.holdout.with.sin <- time.predict(fitted.model=matern.fit.with.sin,
predictors = data.frame(t=t.pred.holdout),
time.pred = t.pred.holdout,
scale.pred = "linear")
matplot(pred.holdout.with.sin$time.pred,
cbind(pred.holdout.with.sin$predictions,pred.holdout.with.sin$quantiles),
lty=c("solid","dashed","dashed"),type="l",col=1,ylab="log(Cases)",xlab="Time")
matplot(pred.holdout.with.sin$time.pred,
cbind(pred.holdout.with.sin$predictions,pred.holdout.with.sin$quantiles),
lty=c("solid","dashed","dashed"),type="l",col=1,ylab="log(Cases)",xlab="Time")
points(mal[holdout,]$t,log(mal[holdout,]$Cases),pch=20)
# Bias
mean((pred.holdout.with.sin$predictions-log(mal[holdout,]$Cases)))
# Mean-square error
mean((pred.holdout.with.sin$predictions-log(mal[holdout,]$Cases))^2)
# Bias
mean((pred.holdout.with.sin$predictions-log(mal[holdout,]$Cases)))
# Mean-square error
sqrt(mean((pred.holdout.with.sin$predictions-log(mal[holdout,]$Cases))^2))
matern.fit.train <- fit.matern(form = log(Cases)~t + I((t>50)*(t-50)) + I(t>225)+
minT.lag2 + maxT.lag2 + Rain.lag2,
data=mal[train,],time="t",kappa=2.5,
start.cov.pars=c(1,1),method="nlminb")
t.pred.holdout <- mal$t[holdout]
pred.holdout <- time.predict(fitted.model=matern.fit.train,
predictors = data.frame(t=t.pred.holdout,
minT.lag2=mal$minT.lag2[holdout],
maxT.lag2=mal$maxT.lag2[holdout],
Rain.lag2=mal$Rain.lag2[holdout]),
time.pred = t.pred.holdout,scale.pred = "linear")
matplot(pred.holdout$time.pred,cbind(pred.holdout$predictions,pred.holdout$quantiles),
lty=c("solid","dashed","dashed"),type="l",col=1,
ylab="log(Cases)",xlab="Time")
points(mal[holdout,]$t,log(mal[holdout,]$Cases),pch=20)
# Bias
model_A <- list()
model_A$bias <- mean((pred.holdout$predictions-log(mal[holdout,]$Cases)))
# Mean-square error
model_A$rmse <- sqrt(mean((pred.holdout$predictions-log(mal[holdout,]$Cases))^2))
# Point 4
matern.fit.with.sin <- fit.matern(form=
log(Cases) ~ t+I((t-50)*(t>50))+I(t>229)+sin(2*pi*t/12)+cos(2*pi*t/12)+
sin(2*pi*t/6)+cos(2*pi*t/6),time="t",start.cov.pars = c(1,5),
kappa=2.5,data=mal[train,], # NOTE: selecting the training data
method="nlminb")
pred.holdout.with.sin <- time.predict(fitted.model=matern.fit.with.sin,
predictors = data.frame(t=t.pred.holdout),
time.pred = t.pred.holdout,
scale.pred = "linear")
matplot(pred.holdout.with.sin$time.pred,
cbind(pred.holdout.with.sin$predictions,pred.holdout.with.sin$quantiles),
lty=c("solid","dashed","dashed"),type="l",col=1,ylab="log(Cases)",xlab="Time")
points(mal[holdout,]$t,log(mal[holdout,]$Cases),pch=20)
# Bias
model_B <- list()
model_B$bias <- mean((pred.holdout$predictions-log(mal[holdout,]$Cases)))
# Mean-square error
model_B$rmse <- sqrt(mean((pred.holdout$predictions-log(mal[holdout,]$Cases))^2))
model_A
model_B
# Bias
model_B <- list()
model_B$bias <- mean((pred.holdout.with.sin$predictions-log(mal[holdout,]$Cases)))
# Mean-square error
model_B$rmse <- sqrt(mean((pred.holdout.with.sin$predictions-log(mal[holdout,]$Cases))^2))
model_A
model_B
summary(fit.matern())
get.CI(matern.fit)
